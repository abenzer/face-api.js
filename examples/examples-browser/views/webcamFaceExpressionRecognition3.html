<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/drawing.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <link href="https://fastcdn.org/Animate.css/3.4.0/animate.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Thasadith" rel="stylesheet">

  <script>
      window.onload = function () {
      
      var dps_neutral = []; 
      var dps_sad = []; 
      var dps_angry = []; 
      var dps_happy = []; 
      var dps_surprised = []; 
      var dps_disgusted = []; 
      var dps_fearful = []; 
      var chart = new CanvasJS.Chart("chartContainer", {
        backgroundColor: "transparent",
        axisY: {
          includeZero: true,
          minimum: 0,
          maximum: 1
        },      
        data: [{
          type: "line",
          dataPoints: dps_neutral
        },{
          type: "line",
          dataPoints: dps_happy
        },{
          type: "line",
          dataPoints: dps_sad
        },{
          type: "line",
          dataPoints: dps_angry
        },{
          type: "line",
          dataPoints: dps_surprised
        },{
          type: "line",
          dataPoints: dps_disgusted
        },{
          type: "line",
          dataPoints: dps_fearful
        }]
      });
      
      var xVal = 0;
      var yVal = 1; 
      var updateInterval = 200;
      var dataLength = 50; // number of dataPoints visible at any point
      
      var updateChart = function (count) {
      
        count = count || 1;
      
        for (var j = 0; j < count; j++) {

          // add point: neutral
          yVal = parseFloat($("#emotion_neutral").val());
          dps_neutral.push({
            x: xVal,
            y: yVal
          });
          // add point: happy
          yVal = parseFloat($("#emotion_happy").val());
          dps_happy.push({
            x: xVal,
            y: yVal
          });
          // add point: sad
          yVal = parseFloat($("#emotion_sad").val());
          dps_sad.push({
            x: xVal,
            y: yVal
          });
          // add point: sad
          yVal = parseFloat($("#emotion_angry").val());
          dps_angry.push({
            x: xVal,
            y: yVal
          });
          // add point: sad
          yVal = parseFloat($("#emotion_surprised").val());
          dps_surprised.push({
            x: xVal,
            y: yVal
          });
          // add point: sad
          yVal = parseFloat($("#emotion_disgusted").val());
          dps_disgusted.push({
            x: xVal,
            y: yVal
          });
          // add point: sad
          yVal = parseFloat($("#emotion_fearful").val());
          dps_fearful.push({
            x: xVal,
            y: yVal
          });

          xVal++;

        }
      
        if (dps_neutral.length > dataLength) {
          // dps_neutral.shift();
          // dps_happy.shift();
          // dps_sad.shift();
          // dps_angry.shift();
          // dps_disgusted.shift();
          // dps_surprised.shift();
          // dps_fearful.shift();
        }
      
        chart.render();
      };
      
      updateChart(dataLength);
      setInterval(function(){updateChart()}, updateInterval);
      
      }
      </script>


  <style type='text/css'>
  html {
    overflow-y: hidden;
    color: black;
  }
  #controls {
    position: absolute;
    right: 0;
    top: 0;
    font-size: 1rem;
    z-index: 99999;
  }
  #controls button {
    color: #000;
    background-color: #fff;
    margin: 1rem;
    border: none;
    font-size: .8rem;
    padding: .5rem 1rem;
  }
  :-webkit-full-screen #controls {
    display: none;
  }
  #mainEmotionWrapper {
    display: table;
    position: absolute;
    width: 100vw;
    height: 100vh;
    top: 0;
    left: 0;
    z-index: 999;
    transition: background-color 2s, color 2s;
    background-color: black;
    font-size: 30vw;
  }
  #mainEmotion {
    display: table-cell;
    vertical-align: middle;
    text-align: center;
    width: 100%;
    font-family: 'Thasadith', sans-serif;
  }
  .calm {
    background-color: #eee2d7 !important;
    color: white;
  }
  .pleased {
    background-color: greenyellow !important;
    color: orange;
    font-size: 20vw !important;
  }
  .sad {
    background-color: blue !important;
    color: darkcyan;
  }
  .surprised {
    background-color: turquoise !important;
    color: #ff4d8c;
    font-size: 20vw !important;
  }
  .angry {
    background-color: orangered !important;
    color: white;
  }
  .disgusted {
    background-color: #654321 !important;
    color: #2f2011;
    font-size: 20vw !important;
  }
  .fearful {
    background-color: black !important;
    color: white;
    font-size: 20vw !important;
  }
  #graph {
    position: absolute;
    left: 0;
    top: 0;
    height: 100vh;
    width: 100vw;
    z-index: 9999;
    transition: opacity 1s;
    display: none;
  }
  #graph.visible {
    display: block;
  }
  #graph #chartContainer {
    height: 50vh !important;
  }
  </style>

  <script>
    var elem = document.documentElement;
    /* View in fullscreen */
    function openFullscreen() {
      if (elem.requestFullscreen) {
        elem.requestFullscreen();
      } else if (elem.mozRequestFullScreen) { /* Firefox */
        elem.mozRequestFullScreen();
      } else if (elem.webkitRequestFullscreen) { /* Chrome, Safari and Opera */
        elem.webkitRequestFullscreen();
      } else if (elem.msRequestFullscreen) { /* IE/Edge */
        elem.msRequestFullscreen();
      }
    }
    /* Close fullscreen */
    function closeFullscreen() {
      if (document.exitFullscreen) {
        document.exitFullscreen();
      } else if (document.mozCancelFullScreen) { /* Firefox */
        document.mozCancelFullScreen();
      } else if (document.webkitExitFullscreen) { /* Chrome, Safari and Opera */
        document.webkitExitFullscreen();
      } else if (document.msExitFullscreen) { /* IE/Edge */
        document.msExitFullscreen();
      }
    }
    function toggleGraph() {
      if($("#graph").hasClass("visible")) {
        $("#graph").removeClass("visible");
      } else {
        $("#graph").addClass("visible");
      }
    }
  </script>

</head>
<body>
  <div id="navbar"></div>
  <div class="center-content page-container">

    <div class="progress" id="loader">
      <div class="indeterminate"></div>
    </div>
    <div style="position: relative" class="margin">
      <video onplay="onPlay(this)" id="inputVideo" autoplay muted></video>
      <canvas id="overlay" />
    </div>

    <div id="mainEmotionWrapper">
      <div id="mainEmotion"></div>
    </div>

    <div id="controls">
      <button onClick="toggleGraph()">Toggle graph</button>
      <button onClick="openFullscreen()">Full screen</button>
    </div>

    <div id="graph">
      <div id="chartContainer" style="height: 300px; width: 100%;"></div>
      <script src="https://canvasjs.com/assets/script/canvasjs.min.js"></script>
    </div>
    
    Neutral: <input type="text" id="emotion_neutral" value="" /><br />
    Sad: <input type="text" id="emotion_sad" value="" /><br />
    Angry: <input type="text" id="emotion_happy" value="" /><br />
    Happy: <input type="text" id="emotion_angry" value="" /><br />
    Surprised: <input type="text" id="emotion_surprised" value="" /><br />
    Disgusted: <input type="text" id="emotion_disgusted" value="" /><br />
    Fearful: <input type="text" id="emotion_fearful" value="" />

  </body>

  <script>
    let forwardTimes = []
    let withBoxes = true

    function onChangeHideBoundingBoxes(e) {
      withBoxes = !$(e.target).prop('checked')
    }

    function updateTimeStats(timeInMs) {
      forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
      const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
      $('#time').val(`${Math.round(avgTimeInMs)} ms`)
      $('#fps').val(`${faceapi.round(10000 / avgTimeInMs)}`)
    }

    async function onPlay() {
      const videoEl = $('#inputVideo').get(0)

      if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
        return setTimeout(() => onPlay())

      const options = getFaceDetectorOptions()
      const ts = Date.now()
      const result = await faceapi.detectSingleFace(videoEl, options).withFaceExpressions()

      updateTimeStats(Date.now() - ts)

      if(result) {
        for(i=0;i<7;i++) {
          var expression = result.expressions[i].expression;
          var probability = result.expressions[i].probability;
          $("#emotion_" + expression).val(probability);
        }
        result.expressions.sort(function(a, b){
          return b.probability-a.probability
        })
        var primaryEmotion = result.expressions[0].expression;

        switch(primaryEmotion) {
          case "neutral":
            primaryEmotion = "calm"; break;
          case "happy":
            primaryEmotion = "pleased"; break;  
          case "angry":
            primaryEmotion = "disgusted"; break;
        }

        if(!$("#mainEmotionWrapper").hasClass(primaryEmotion)) {
          $("#mainEmotionWrapper").removeClass();
          $("#mainEmotionWrapper").addClass(primaryEmotion);
          $("#mainEmotion").html(primaryEmotion);
        }

        // console.log(result);
      }

      if (result) {
        drawExpressions(videoEl, $('#overlay').get(0), [result], withBoxes)
      }

      setTimeout(() => onPlay())
    }

    async function run() {
      // load face detection and face expression recognition models
      await changeFaceDetector(TINY_FACE_DETECTOR)
      await faceapi.loadFaceExpressionModel('/')
      changeInputSize(224)

      // try to access users webcam and stream the images
      // to the video element
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
      const videoEl = $('#inputVideo').get(0)
      videoEl.srcObject = stream
    }

    function updateResults() {

    }

    $(document).ready(function() {
      renderNavBar('#navbar', 'webcam_face_expression_recognition')
      initFaceDetectionControls()
      run()
    })
  </script>
</body>
</html>